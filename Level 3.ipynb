{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wqi_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Alky pH 4.5</th>\n",
       "      <th>Chloride Ion</th>\n",
       "      <th>Orthophospht</th>\n",
       "      <th>Sulphate SO4</th>\n",
       "      <th>Ammonia(N)</th>\n",
       "      <th>TurbidityNTU</th>\n",
       "      <th>Temp Water</th>\n",
       "      <th>Cond @ 25C</th>\n",
       "      <th>...</th>\n",
       "      <th>BOD ATU</th>\n",
       "      <th>COD as O2</th>\n",
       "      <th>Nitrate-N</th>\n",
       "      <th>Nitrite-N</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>SALinsitu</th>\n",
       "      <th>ALL_RUNS</th>\n",
       "      <th>Average_count</th>\n",
       "      <th>WQI</th>\n",
       "      <th>WQI clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>181.490909</td>\n",
       "      <td>113.369841</td>\n",
       "      <td>0.504410</td>\n",
       "      <td>71.920000</td>\n",
       "      <td>1.184673</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>7.390233</td>\n",
       "      <td>1087.367089</td>\n",
       "      <td>...</td>\n",
       "      <td>16.172447</td>\n",
       "      <td>140.811111</td>\n",
       "      <td>10.844410</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>283.500000</td>\n",
       "      <td>14.195000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.573738</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>220.684211</td>\n",
       "      <td>142.301587</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>886.400000</td>\n",
       "      <td>2.830066</td>\n",
       "      <td>9.246154</td>\n",
       "      <td>9.044861</td>\n",
       "      <td>1176.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.575197</td>\n",
       "      <td>66.107143</td>\n",
       "      <td>10.654855</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>22.524549</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>56.197425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-16</td>\n",
       "      <td>216.928571</td>\n",
       "      <td>361.460000</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>118.950000</td>\n",
       "      <td>1.355232</td>\n",
       "      <td>35.100000</td>\n",
       "      <td>4.559789</td>\n",
       "      <td>1490.131343</td>\n",
       "      <td>...</td>\n",
       "      <td>22.517364</td>\n",
       "      <td>147.395833</td>\n",
       "      <td>10.564346</td>\n",
       "      <td>0.068554</td>\n",
       "      <td>313.025758</td>\n",
       "      <td>23.973000</td>\n",
       "      <td>29.954545</td>\n",
       "      <td>28.863636</td>\n",
       "      <td>5.273402</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2012-01-17</td>\n",
       "      <td>235.390244</td>\n",
       "      <td>162.814286</td>\n",
       "      <td>0.819191</td>\n",
       "      <td>213.333333</td>\n",
       "      <td>4.351483</td>\n",
       "      <td>16.451852</td>\n",
       "      <td>3.959510</td>\n",
       "      <td>1156.449383</td>\n",
       "      <td>...</td>\n",
       "      <td>17.923786</td>\n",
       "      <td>113.724561</td>\n",
       "      <td>9.471521</td>\n",
       "      <td>0.049162</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>22.524549</td>\n",
       "      <td>12.125000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>31.841305</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2012-01-23</td>\n",
       "      <td>224.803922</td>\n",
       "      <td>105.854167</td>\n",
       "      <td>0.460703</td>\n",
       "      <td>95.354545</td>\n",
       "      <td>1.112021</td>\n",
       "      <td>9.292308</td>\n",
       "      <td>6.882867</td>\n",
       "      <td>1002.506849</td>\n",
       "      <td>...</td>\n",
       "      <td>5.865691</td>\n",
       "      <td>32.183673</td>\n",
       "      <td>8.754667</td>\n",
       "      <td>0.061222</td>\n",
       "      <td>399.181818</td>\n",
       "      <td>30.526250</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>38.055600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1933</td>\n",
       "      <td>2022-07-09</td>\n",
       "      <td>202.702330</td>\n",
       "      <td>290.161737</td>\n",
       "      <td>0.395029</td>\n",
       "      <td>287.018100</td>\n",
       "      <td>2.840500</td>\n",
       "      <td>10.138017</td>\n",
       "      <td>18.425000</td>\n",
       "      <td>1115.134319</td>\n",
       "      <td>...</td>\n",
       "      <td>7.531000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>8.194472</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>313.025758</td>\n",
       "      <td>22.524549</td>\n",
       "      <td>25.342105</td>\n",
       "      <td>22.355263</td>\n",
       "      <td>51.555623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1955</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>202.702330</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>0.395029</td>\n",
       "      <td>287.018100</td>\n",
       "      <td>1.200429</td>\n",
       "      <td>10.138017</td>\n",
       "      <td>18.075000</td>\n",
       "      <td>1115.134319</td>\n",
       "      <td>...</td>\n",
       "      <td>4.310390</td>\n",
       "      <td>49.272727</td>\n",
       "      <td>8.194472</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>313.025758</td>\n",
       "      <td>33.933750</td>\n",
       "      <td>55.027027</td>\n",
       "      <td>54.837838</td>\n",
       "      <td>49.640626</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1976</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>202.702330</td>\n",
       "      <td>290.161737</td>\n",
       "      <td>0.395029</td>\n",
       "      <td>287.018100</td>\n",
       "      <td>2.901286</td>\n",
       "      <td>10.138017</td>\n",
       "      <td>18.841667</td>\n",
       "      <td>1115.134319</td>\n",
       "      <td>...</td>\n",
       "      <td>5.391538</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>8.194472</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>313.025758</td>\n",
       "      <td>32.533333</td>\n",
       "      <td>34.545455</td>\n",
       "      <td>11.727273</td>\n",
       "      <td>62.415078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2012</td>\n",
       "      <td>2022-11-05</td>\n",
       "      <td>202.702330</td>\n",
       "      <td>290.161737</td>\n",
       "      <td>0.395029</td>\n",
       "      <td>287.018100</td>\n",
       "      <td>3.107000</td>\n",
       "      <td>10.138017</td>\n",
       "      <td>13.281250</td>\n",
       "      <td>1115.134319</td>\n",
       "      <td>...</td>\n",
       "      <td>5.100625</td>\n",
       "      <td>30.153846</td>\n",
       "      <td>8.194472</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>313.025758</td>\n",
       "      <td>34.711667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.799889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2017</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>171.810345</td>\n",
       "      <td>51.918750</td>\n",
       "      <td>0.157196</td>\n",
       "      <td>287.018100</td>\n",
       "      <td>1.709603</td>\n",
       "      <td>10.138017</td>\n",
       "      <td>11.412338</td>\n",
       "      <td>1651.967742</td>\n",
       "      <td>...</td>\n",
       "      <td>11.921057</td>\n",
       "      <td>112.523810</td>\n",
       "      <td>4.187520</td>\n",
       "      <td>0.035396</td>\n",
       "      <td>275.600000</td>\n",
       "      <td>27.083500</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>10.374529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        Date  Alky pH 4.5  Chloride Ion  Orthophospht  \\\n",
       "0             2  2012-01-05   181.490909    113.369841      0.504410   \n",
       "1             5  2012-01-09   220.684211    142.301587      0.819167   \n",
       "2             8  2012-01-16   216.928571    361.460000      0.476744   \n",
       "3             9  2012-01-17   235.390244    162.814286      0.819191   \n",
       "4            13  2012-01-23   224.803922    105.854167      0.460703   \n",
       "..          ...         ...          ...           ...           ...   \n",
       "326        1933  2022-07-09   202.702330    290.161737      0.395029   \n",
       "327        1955  2022-08-06   202.702330    174.000000      0.395029   \n",
       "328        1976  2022-09-10   202.702330    290.161737      0.395029   \n",
       "329        2012  2022-11-05   202.702330    290.161737      0.395029   \n",
       "330        2017  2022-11-14   171.810345     51.918750      0.157196   \n",
       "\n",
       "     Sulphate SO4  Ammonia(N)  TurbidityNTU  Temp Water   Cond @ 25C  ...  \\\n",
       "0       71.920000    1.184673     14.750000    7.390233  1087.367089  ...   \n",
       "1      886.400000    2.830066      9.246154    9.044861  1176.500000  ...   \n",
       "2      118.950000    1.355232     35.100000    4.559789  1490.131343  ...   \n",
       "3      213.333333    4.351483     16.451852    3.959510  1156.449383  ...   \n",
       "4       95.354545    1.112021      9.292308    6.882867  1002.506849  ...   \n",
       "..            ...         ...           ...         ...          ...  ...   \n",
       "326    287.018100    2.840500     10.138017   18.425000  1115.134319  ...   \n",
       "327    287.018100    1.200429     10.138017   18.075000  1115.134319  ...   \n",
       "328    287.018100    2.901286     10.138017   18.841667  1115.134319  ...   \n",
       "329    287.018100    3.107000     10.138017   13.281250  1115.134319  ...   \n",
       "330    287.018100    1.709603     10.138017   11.412338  1651.967742  ...   \n",
       "\n",
       "       BOD ATU   COD as O2  Nitrate-N  Nitrite-N    Hardness  SALinsitu  \\\n",
       "0    16.172447  140.811111  10.844410   0.068047  283.500000  14.195000   \n",
       "1     7.575197   66.107143  10.654855   0.063292  307.000000  22.524549   \n",
       "2    22.517364  147.395833  10.564346   0.068554  313.025758  23.973000   \n",
       "3    17.923786  113.724561   9.471521   0.049162  347.000000  22.524549   \n",
       "4     5.865691   32.183673   8.754667   0.061222  399.181818  30.526250   \n",
       "..         ...         ...        ...        ...         ...        ...   \n",
       "326   7.531000   74.000000   8.194472   0.063292  313.025758  22.524549   \n",
       "327   4.310390   49.272727   8.194472   0.063292  313.025758  33.933750   \n",
       "328   5.391538   42.500000   8.194472   0.063292  313.025758  32.533333   \n",
       "329   5.100625   30.153846   8.194472   0.063292  313.025758  34.711667   \n",
       "330  11.921057  112.523810   4.187520   0.035396  275.600000  27.083500   \n",
       "\n",
       "      ALL_RUNS  Average_count        WQI  WQI clf  \n",
       "0     1.333333       1.333333   0.573738        3  \n",
       "1    45.000000      45.000000  56.197425        1  \n",
       "2    29.954545      28.863636   5.273402        3  \n",
       "3    12.125000       6.500000  31.841305        2  \n",
       "4     2.200000       1.400000  38.055600        2  \n",
       "..         ...            ...        ...      ...  \n",
       "326  25.342105      22.355263  51.555623        1  \n",
       "327  55.027027      54.837838  49.640626        2  \n",
       "328  34.545455      11.727273  62.415078        1  \n",
       "329   2.000000       1.000000  64.799889        1  \n",
       "330  23.000000      11.500000  10.374529        3  \n",
       "\n",
       "[331 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns={\"ALL_RUNS\",\"Unnamed: 0\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "Alky pH 4.5      0\n",
       "Chloride Ion     0\n",
       "Orthophospht     0\n",
       "Sulphate SO4     0\n",
       "Ammonia(N)       0\n",
       "TurbidityNTU     0\n",
       "Temp Water       0\n",
       "Cond @ 25C       0\n",
       "Oxygen Diss      0\n",
       "pH               0\n",
       "BOD ATU          0\n",
       "COD as O2        0\n",
       "Nitrate-N        0\n",
       "Nitrite-N        0\n",
       "Hardness         0\n",
       "SALinsitu        0\n",
       "Average_count    0\n",
       "WQI              0\n",
       "WQI clf          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Alky pH 4.5', 'Chloride Ion', 'Orthophospht', 'Sulphate SO4',\n",
       "       'Ammonia(N)', 'TurbidityNTU', 'Temp Water', 'Cond @ 25C', 'Oxygen Diss',\n",
       "       'pH', 'BOD ATU', 'COD as O2', 'Nitrate-N', 'Nitrite-N', 'Hardness',\n",
       "       'SALinsitu', 'Average_count', 'WQI', 'WQI clf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['year'] = df.Date.dt.year\n",
    "# df['month'] = df.Date.dt.month\n",
    "# df['day'] = df.Date.dt.day\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Alky pH 4.5', 'Chloride Ion', 'Orthophospht', 'Sulphate SO4',\n",
    "       'Ammonia(N)', 'TurbidityNTU', 'Temp Water', 'Cond @ 25C', 'Oxygen Diss',\n",
    "       'pH', 'BOD ATU', 'COD as O2', 'Nitrate-N', 'Nitrite-N', 'Hardness',\n",
    "       'SALinsitu']\n",
    "# X = df[cols]\n",
    "# y = pd.DataFrame(df['WQI clf'])\n",
    "\n",
    "X = df[cols]\n",
    "\n",
    "y_wqi = pd.DataFrame(df['WQI'])\n",
    "\n",
    "y_clf = df['WQI clf']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, _X, _y, _cv=5):\n",
    "      '''Function to perform 5 Folds Cross-Validation\n",
    "       Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "      scoring = ['neg_mean_absolute_error']\n",
    "      results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=5,\n",
    "                               scoring=scoring,\n",
    "                               return_train_score=True,\n",
    "                              )\n",
    "      \n",
    "      return {\n",
    "          \"test_mae_mean\" : -1 *results['test_neg_mean_absolute_error'].mean(), \n",
    "          \"test_mae_std\" : results['test_neg_mean_absolute_error'].std()\n",
    "          \n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_wqi, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6056719517612318\n",
      "MSE: 0.36683851315025995\n",
      "MAE: 0.43902749675458863\n",
      "R-squared: 0.4908045499284117\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of SVR and fit the training data\n",
    "svr = SVR(kernel='linear', C=1.0)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict on the testing data\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred_svr)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_svr))\n",
    "r2 = r2_score(y_test, y_pred_svr)\n",
    "mae = mean_absolute_error(y_test, y_pred_svr)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.47625193872295013\n",
      "MSE: 0.22681590913736863\n",
      "MAE: 0.2980462751870514\n",
      "R-squared: 0.6851649300811231\n"
     ]
    }
   ],
   "source": [
    "# Create a linear regression model and fit the data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Use the trained model to predict on the testing data\n",
    "y_pred_ml = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model \n",
    "mse = mean_squared_error(y_test, y_pred_ml)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_ml))\n",
    "r2 = r2_score(y_test, y_pred_ml)\n",
    "mae = mean_absolute_error(y_test, y_pred_ml)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tress regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8375515132297433\n",
      "MSE: 0.7014925373134329\n",
      "MAE: 0.4626865671641791\n",
      "R-squared: 0.026283240568954924\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree regressor model and fit the training data\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_dt = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred_dt)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "mse = mean_squared_error(y_test, y_pred_dt)\n",
    "mae = mean_absolute_error(y_test, y_pred_dt)\n",
    "r2 = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5142071131595523\n",
      "MSE: 0.2644089552238806\n",
      "MAE: 0.3617910447761194\n",
      "R-squared: 0.6329833642547928\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest  regression model and cross validate the data\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)\n",
    "\n",
    "\n",
    "lg = LGBMRegressor(random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5416582320907857\n",
      "MSE: 0.29339364039171545\n",
      "MAE: 0.3597759961238674\n",
      "R-squared: 0.5927507570444\n"
     ]
    }
   ],
   "source": [
    "# Create a LGBM regression model and cross validate the data\n",
    "model = LGBMRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_lgbm = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred_lgbm)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_lgbm))\n",
    "mse = mean_squared_error(y_test, y_pred_lgbm)\n",
    "mae = mean_absolute_error(y_test, y_pred_lgbm)\n",
    "r2 = r2_score(y_test, y_pred_lgbm)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_clf, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7431277184778867\n",
      "MSE: 0.5522388059701493\n",
      "MAE: 0.373134328358209\n",
      "R-squared: 0.233457019171305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a Logistic Regression model object\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Train the model using training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels for test data\n",
    "y_pred_clg = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred_clg)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_clg))\n",
    "mse = mean_squared_error(y_test, y_pred_clg)\n",
    "mae = mean_absolute_error(y_test, y_pred_clg)\n",
    "r2 = r2_score(y_test, y_pred_clg)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8011186209146055\n",
      "MSE: 0.6417910447761194\n",
      "MAE: 0.43283582089552236\n",
      "R-squared: 0.10915275200989494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a Decision Tree Classifier object\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model using training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels for test data\n",
    "y_pred_dtc = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred_dtc)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_dtc))\n",
    "mse = mean_squared_error(y_test, y_pred_dtc)\n",
    "mae = mean_absolute_error(y_test, y_pred_dtc)\n",
    "r2 = r2_score(y_test, y_pred_dtc)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5859040724295678\n",
      "MSE: 0.34328358208955223\n",
      "MAE: 0.2835820895522388\n",
      "R-squared: 0.5235003092145949\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest Classifier object\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Train the model using training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels for test data\n",
    "y_pred_rfc = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred_rfc)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rfc))\n",
    "mse = mean_squared_error(y_test, y_pred_rfc)\n",
    "mae = mean_absolute_error(y_test, y_pred_rfc)\n",
    "r2 = r2_score(y_test, y_pred_rfc)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### support vector classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8551861104941366\n",
      "MSE: 0.7313432835820896\n",
      "MAE: 0.6119402985074627\n",
      "R-squared: -0.015151515151515138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an SVM object\n",
    "svm = SVC()\n",
    "\n",
    "# Train the model using training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels for test data\n",
    "y_pred_svc = svm.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred_svc)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_svc))\n",
    "mse = mean_squared_error(y_test, y_pred_svc)\n",
    "mae = mean_absolute_error(y_test, y_pred_svc)\n",
    "r2 = r2_score(y_test, y_pred_svc)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.922359077939127\n",
      "MSE: 0.8507462686567164\n",
      "MAE: 0.5522388059701493\n",
      "R-squared: -0.18089053803339517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create a Gaussian Naive Bayes object\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model using training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels for test data\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred_nb)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_nb))\n",
    "mse = mean_squared_error(y_test, y_pred_nb)\n",
    "mae = mean_absolute_error(y_test, y_pred_nb)\n",
    "r2 = r2_score(y_test, y_pred_nb)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:55:26.385492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 20:55:26.595794: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-24 20:55:26.649268: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-24 20:55:27.764030: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 20:55:28.797052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 94 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2023-04-24 20:55:28.798200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 42316 MB memory:  -> device: 1, name: NVIDIA A40, pci bus id: 0000:ca:00.0, compute capability: 8.6\n",
      "2023-04-24 20:55:28.826392: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 94.81M (99418112 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 16)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [109], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Train the model using training data\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Predict the class labels for test data\u001b[39;00m\n\u001b[1;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_classes(X_test)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file3uhpd08h.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 16)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a Sequential model object\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(tf.keras.layers.Dense(units=64, activation='relu', input_dim=10))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using training data\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict the class labels for test data\n",
    "y_pred = model.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples before resampling: 331\n",
      "Number of samples after resampling: 602\n"
     ]
    }
   ],
   "source": [
    "# Separate the features and target variable\n",
    "# X = data.drop('target', axis=1)\n",
    "# y = data['target']\n",
    "# !!pip install imblearn\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "#convert y values to categorical values\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y_transformed = lab.fit_transform(y_clf)\n",
    "# Instantiate the ADASYN class\n",
    "adasyn = ADASYN()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X, y_clf)\n",
    "\n",
    "# Print the number of samples before and after resampling\n",
    "print(\"Number of samples before resampling:\", len(X))\n",
    "print(\"Number of samples after resampling:\", len(X_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.to_csv('resampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alky pH 4.5</th>\n",
       "      <th>Chloride Ion</th>\n",
       "      <th>Orthophospht</th>\n",
       "      <th>Sulphate SO4</th>\n",
       "      <th>Ammonia(N)</th>\n",
       "      <th>TurbidityNTU</th>\n",
       "      <th>Temp Water</th>\n",
       "      <th>Cond @ 25C</th>\n",
       "      <th>Oxygen Diss</th>\n",
       "      <th>pH</th>\n",
       "      <th>BOD ATU</th>\n",
       "      <th>COD as O2</th>\n",
       "      <th>Nitrate-N</th>\n",
       "      <th>Nitrite-N</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>SALinsitu</th>\n",
       "      <th>WQI</th>\n",
       "      <th>WQI clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181.490909</td>\n",
       "      <td>113.369841</td>\n",
       "      <td>0.504410</td>\n",
       "      <td>71.920000</td>\n",
       "      <td>1.184673</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>7.390233</td>\n",
       "      <td>1087.367089</td>\n",
       "      <td>10.031494</td>\n",
       "      <td>7.860330</td>\n",
       "      <td>16.172447</td>\n",
       "      <td>140.811111</td>\n",
       "      <td>10.844410</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>283.500000</td>\n",
       "      <td>14.195000</td>\n",
       "      <td>0.573738</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.684211</td>\n",
       "      <td>142.301587</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>886.400000</td>\n",
       "      <td>2.830066</td>\n",
       "      <td>9.246154</td>\n",
       "      <td>9.044861</td>\n",
       "      <td>1176.500000</td>\n",
       "      <td>10.089863</td>\n",
       "      <td>7.884348</td>\n",
       "      <td>7.575197</td>\n",
       "      <td>66.107143</td>\n",
       "      <td>10.654855</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>22.524549</td>\n",
       "      <td>56.197425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216.928571</td>\n",
       "      <td>361.460000</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>118.950000</td>\n",
       "      <td>1.355232</td>\n",
       "      <td>35.100000</td>\n",
       "      <td>4.559789</td>\n",
       "      <td>1490.131343</td>\n",
       "      <td>11.696173</td>\n",
       "      <td>7.743488</td>\n",
       "      <td>22.517364</td>\n",
       "      <td>147.395833</td>\n",
       "      <td>10.564346</td>\n",
       "      <td>0.068554</td>\n",
       "      <td>313.025758</td>\n",
       "      <td>23.973000</td>\n",
       "      <td>5.273402</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235.390244</td>\n",
       "      <td>162.814286</td>\n",
       "      <td>0.819191</td>\n",
       "      <td>213.333333</td>\n",
       "      <td>4.351483</td>\n",
       "      <td>16.451852</td>\n",
       "      <td>3.959510</td>\n",
       "      <td>1156.449383</td>\n",
       "      <td>12.124239</td>\n",
       "      <td>7.839619</td>\n",
       "      <td>17.923786</td>\n",
       "      <td>113.724561</td>\n",
       "      <td>9.471521</td>\n",
       "      <td>0.049162</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>22.524549</td>\n",
       "      <td>31.841305</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>224.803922</td>\n",
       "      <td>105.854167</td>\n",
       "      <td>0.460703</td>\n",
       "      <td>95.354545</td>\n",
       "      <td>1.112021</td>\n",
       "      <td>9.292308</td>\n",
       "      <td>6.882867</td>\n",
       "      <td>1002.506849</td>\n",
       "      <td>9.910886</td>\n",
       "      <td>7.890313</td>\n",
       "      <td>5.865691</td>\n",
       "      <td>32.183673</td>\n",
       "      <td>8.754667</td>\n",
       "      <td>0.061222</td>\n",
       "      <td>399.181818</td>\n",
       "      <td>30.526250</td>\n",
       "      <td>38.055600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>192.572566</td>\n",
       "      <td>164.884623</td>\n",
       "      <td>0.078094</td>\n",
       "      <td>287.018100</td>\n",
       "      <td>1.728049</td>\n",
       "      <td>10.138017</td>\n",
       "      <td>9.964029</td>\n",
       "      <td>1627.458106</td>\n",
       "      <td>9.540230</td>\n",
       "      <td>7.653206</td>\n",
       "      <td>11.788106</td>\n",
       "      <td>114.291903</td>\n",
       "      <td>6.880556</td>\n",
       "      <td>0.027401</td>\n",
       "      <td>300.753510</td>\n",
       "      <td>26.231837</td>\n",
       "      <td>8.998514</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>192.849920</td>\n",
       "      <td>20.134155</td>\n",
       "      <td>0.089404</td>\n",
       "      <td>287.018100</td>\n",
       "      <td>1.124294</td>\n",
       "      <td>8.133829</td>\n",
       "      <td>14.536357</td>\n",
       "      <td>324.132946</td>\n",
       "      <td>10.012088</td>\n",
       "      <td>7.667425</td>\n",
       "      <td>10.439801</td>\n",
       "      <td>172.343685</td>\n",
       "      <td>7.071581</td>\n",
       "      <td>0.017464</td>\n",
       "      <td>318.772006</td>\n",
       "      <td>28.357869</td>\n",
       "      <td>6.381011</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>201.468153</td>\n",
       "      <td>240.401592</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>1048.105366</td>\n",
       "      <td>2.886396</td>\n",
       "      <td>10.094952</td>\n",
       "      <td>10.130083</td>\n",
       "      <td>1117.035717</td>\n",
       "      <td>9.765357</td>\n",
       "      <td>7.819835</td>\n",
       "      <td>17.236249</td>\n",
       "      <td>182.671022</td>\n",
       "      <td>7.013061</td>\n",
       "      <td>0.061927</td>\n",
       "      <td>311.646505</td>\n",
       "      <td>25.438081</td>\n",
       "      <td>5.870344</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>181.895126</td>\n",
       "      <td>71.474484</td>\n",
       "      <td>0.330955</td>\n",
       "      <td>100.041733</td>\n",
       "      <td>3.770544</td>\n",
       "      <td>3.676516</td>\n",
       "      <td>11.977388</td>\n",
       "      <td>689.899998</td>\n",
       "      <td>11.461038</td>\n",
       "      <td>8.036840</td>\n",
       "      <td>16.554649</td>\n",
       "      <td>323.546080</td>\n",
       "      <td>4.754899</td>\n",
       "      <td>0.036291</td>\n",
       "      <td>324.100706</td>\n",
       "      <td>23.533076</td>\n",
       "      <td>4.084403</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>209.779260</td>\n",
       "      <td>247.211683</td>\n",
       "      <td>0.879553</td>\n",
       "      <td>529.463932</td>\n",
       "      <td>2.154388</td>\n",
       "      <td>3.564658</td>\n",
       "      <td>14.982773</td>\n",
       "      <td>1564.918735</td>\n",
       "      <td>8.246432</td>\n",
       "      <td>7.802287</td>\n",
       "      <td>16.829077</td>\n",
       "      <td>142.959790</td>\n",
       "      <td>11.302231</td>\n",
       "      <td>0.090375</td>\n",
       "      <td>429.087590</td>\n",
       "      <td>32.256885</td>\n",
       "      <td>0.854798</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alky pH 4.5  Chloride Ion  Orthophospht  Sulphate SO4  Ammonia(N)  \\\n",
       "0     181.490909    113.369841      0.504410     71.920000    1.184673   \n",
       "1     220.684211    142.301587      0.819167    886.400000    2.830066   \n",
       "2     216.928571    361.460000      0.476744    118.950000    1.355232   \n",
       "3     235.390244    162.814286      0.819191    213.333333    4.351483   \n",
       "4     224.803922    105.854167      0.460703     95.354545    1.112021   \n",
       "..           ...           ...           ...           ...         ...   \n",
       "597   192.572566    164.884623      0.078094    287.018100    1.728049   \n",
       "598   192.849920     20.134155      0.089404    287.018100    1.124294   \n",
       "599   201.468153    240.401592      0.384434   1048.105366    2.886396   \n",
       "600   181.895126     71.474484      0.330955    100.041733    3.770544   \n",
       "601   209.779260    247.211683      0.879553    529.463932    2.154388   \n",
       "\n",
       "     TurbidityNTU  Temp Water   Cond @ 25C  Oxygen Diss        pH    BOD ATU  \\\n",
       "0       14.750000    7.390233  1087.367089    10.031494  7.860330  16.172447   \n",
       "1        9.246154    9.044861  1176.500000    10.089863  7.884348   7.575197   \n",
       "2       35.100000    4.559789  1490.131343    11.696173  7.743488  22.517364   \n",
       "3       16.451852    3.959510  1156.449383    12.124239  7.839619  17.923786   \n",
       "4        9.292308    6.882867  1002.506849     9.910886  7.890313   5.865691   \n",
       "..            ...         ...          ...          ...       ...        ...   \n",
       "597     10.138017    9.964029  1627.458106     9.540230  7.653206  11.788106   \n",
       "598      8.133829   14.536357   324.132946    10.012088  7.667425  10.439801   \n",
       "599     10.094952   10.130083  1117.035717     9.765357  7.819835  17.236249   \n",
       "600      3.676516   11.977388   689.899998    11.461038  8.036840  16.554649   \n",
       "601      3.564658   14.982773  1564.918735     8.246432  7.802287  16.829077   \n",
       "\n",
       "      COD as O2  Nitrate-N  Nitrite-N    Hardness  SALinsitu        WQI  \\\n",
       "0    140.811111  10.844410   0.068047  283.500000  14.195000   0.573738   \n",
       "1     66.107143  10.654855   0.063292  307.000000  22.524549  56.197425   \n",
       "2    147.395833  10.564346   0.068554  313.025758  23.973000   5.273402   \n",
       "3    113.724561   9.471521   0.049162  347.000000  22.524549  31.841305   \n",
       "4     32.183673   8.754667   0.061222  399.181818  30.526250  38.055600   \n",
       "..          ...        ...        ...         ...        ...        ...   \n",
       "597  114.291903   6.880556   0.027401  300.753510  26.231837   8.998514   \n",
       "598  172.343685   7.071581   0.017464  318.772006  28.357869   6.381011   \n",
       "599  182.671022   7.013061   0.061927  311.646505  25.438081   5.870344   \n",
       "600  323.546080   4.754899   0.036291  324.100706  23.533076   4.084403   \n",
       "601  142.959790  11.302231   0.090375  429.087590  32.256885   0.854798   \n",
       "\n",
       "     WQI clf  \n",
       "0          3  \n",
       "1          1  \n",
       "2          3  \n",
       "3          2  \n",
       "4          2  \n",
       "..       ...  \n",
       "597        3  \n",
       "598        3  \n",
       "599        3  \n",
       "600        3  \n",
       "601        3  \n",
       "\n",
       "[602 rows x 18 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
